---
description: 
globs: 
alwaysApply: true
---
---
name: "Optimization Principles for Dataset Forge"
description: Apply DRY and SOLID principles to optimize and maintain Dataset Forge code structure
globs: ["**/*.py"]
alwaysApply: true
priority: 3
---

# Optimization Principles for Dataset Forge

## Core Principles

### DRY (Dont Repeat Yourself)
- **Centralized Utilities**: Use dataset_forge.utils for common functionality
- **Shared Patterns**: Implement reusable patterns for memory management, progress tracking, and error handling
- **Configuration Management**: Use centralized session state and configuration files
- **Template Functions**: Create reusable functions for common operations

### SOLID Principles

#### Single Responsibility Principle
- **Menu Functions**: Handle only UI interaction and user input
- **Action Functions**: Handle only business logic and data processing
- **Utility Functions**: Handle only specific utility operations
- **Test Functions**: Handle only testing of specific functionality

#### Open/Closed Principle
- **Extensible Architecture**: Design modules to be extended without modification
- **Plugin System**: Support for additional DPID implementations and utilities
- **Configurable Behavior**: Use configuration files for customizable behavior

#### Liskov Substitution Principle
- **Interface Consistency**: Ensure all implementations follow the same interface
- **Type Safety**: Use proper type hints and abstract base classes
- **Error Handling**: Consistent error handling across all implementations

#### Interface Segregation Principle
- **Focused Interfaces**: Create specific interfaces for specific use cases
- **Minimal Dependencies**: Import only what you need
- **Lazy Loading**: Defer heavy imports until needed

#### Dependency Inversion Principle
- **Abstraction Over Implementation**: Depend on abstractions, not concrete implementations
- **Dependency Injection**: Use centralized utilities and configuration
- **Testability**: Design for easy testing and mocking

## Dataset Forge Specific Optimizations

### Memory Management
```python
# Use centralized memory management
from dataset_forge.utils.memory_utils import clear_memory, memory_context, auto_cleanup

@auto_cleanup
def process_large_dataset(images):
    with memory_context("Large Dataset Processing"):
        # Process images in batches
        for batch in chunk_images(images, batch_size=32):
            process_batch(batch)
            clear_memory()  # Clear after each batch
```

### Parallel Processing
```python
# Use centralized parallel processing
from dataset_forge.utils.progress_utils import smart_map, image_map
from dataset_forge.utils.parallel_utils import ProcessingType

# Automatic optimization based on data type
results = smart_map(process_image, image_paths, desc=Processing Images")

# Image-specific optimization
results = image_map(process_image, image_paths, desc=Processing Images")
```

### Caching and Performance
```python
# Use centralized caching
from dataset_forge.utils.cache_utils import in_memory_cache, disk_cache

@in_memory_cache(ttl=300)  # 5 minutes
def expensive_calculation(data):
    # Expensive operation
    return result

@disk_cache(ttl=3600 # 1 hour
def very_expensive_calculation(data):
    # Very expensive operation
    return result
```

### Error Handling
```python
# Use centralized error handling
from dataset_forge.utils.printing import print_error, print_warning
from dataset_forge.utils.history_log import log_operation

def robust_operation():
    try:
        # Operation code
        log_operation("operation_name", Operation details")
        return result
    except FileNotFoundError as e:
        print_error(fFile not found: {e}")
        log_operation("operation_name", f"Failed: {e}")
        return None
    except Exception as e:
        print_error(fUnexpected error: {e}")
        log_operation("operation_name", f"Failed: {e}")
        return None
```

## Performance Optimization Guidelines

### Lazy Loading
- **Menu Imports**: Use lazy_action() for menu functions
- **Heavy Libraries**: Import heavy libraries only when needed
- **Configuration**: Load configuration files on demand

### Batch Processing
- **Large Datasets**: Process data in manageable batches
- **Memory Efficiency**: Clear memory between batches
- **Progress Tracking**: Show progress for long operations

### GPU Acceleration
- **Automatic Detection**: Detect GPU availability automatically
- **Memory Management**: Proper CUDA memory cleanup
- **Fallback Support**: Graceful fallback to CPU when GPU unavailable

### Caching Strategy
- **In-Memory Cache**: For frequently accessed, small data
- **Disk Cache**: For expensive computations and large data
- **Model Cache**: For AI model loading and inference
- **Smart Cache**: Automatic cache strategy selection

## Code Organization Principles

### Modular Design
- **Clear Separation**: menus/ (UI), actions/ (business logic), utils/ (utilities)
- **Single Purpose**: Each module has a single, well-defined purpose
- **Minimal Dependencies**: Minimize cross-module dependencies

### Configuration Management
- **Centralized Config**: Use configs/ directory for all configuration
- **Environment Variables**: Support for environment-based configuration
- **User Preferences**: Store user preferences in session state

### Testing Strategy
- **Unit Tests**: Test individual functions and classes
- **Integration Tests**: Test module interactions
- **CLI Tests**: Test end-to-end workflows
- **Performance Tests**: Test optimization features

## Communication and Problem-Solving

- **Clear Documentation**: Document optimization decisions and trade-offs
- **Performance Monitoring**: Track performance metrics and bottlenecks
- **User Feedback**: Consider user experience in optimization decisions
- **Maintainability**: Balance performance with code maintainability

## Code Quality and Best Practices

- **Type Safety**: Use comprehensive type hints
- **Error Handling**: Robust error handling with meaningful messages
- **Logging**: Comprehensive logging for debugging and monitoring
- **Documentation**: Clear docstrings and usage examples

## Semantic Naming and Abstractions

- **Descriptive Names**: Use clear, descriptive function and variable names
- **Consistent Patterns**: Follow established naming conventions
- **Abstraction Levels**: Choose appropriate abstraction levels
- **Domain Language**: Use domain-specific terminology

## Platform Thinking

- **Cross-Platform**: Ensure compatibility across different platforms
- **Resource Awareness**: Be aware of system resources and limitations
- **Scalability**: Design for scalability and growth
- **Maintainability**: Focus on long-term maintainability

## Response Format

- **Clear Structure**: Organize responses with clear headings and sections
- **Code Examples**: Include practical code examples
- **Explanation**: Explain the reasoning behind optimization decisions
- **Trade-offs**: Discuss benefits and potential drawbacks

## Handling Uncertainty and Limitations

- **Graceful Degradation**: Handle cases where optimization is not possible
- **Fallback Strategies**: Provide fallback options for failed optimizations
- **User Communication**: Clearly communicate limitations and alternatives
- **Continuous Improvement**: Iterate and improve optimization strategies
