#!/usr/bin/env python3
"""
Comprehensive test script for BHI filtering with CUDA optimizations.
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path
from unittest.mock import patch, MagicMock

# Add the project root to the Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import torch
import pytest

from dataset_forge.utils.printing import (
    print_info,
    print_success,
    print_warning,
    print_error,
)
from dataset_forge.actions.bhi_filtering_actions import (
    get_optimal_batch_size,
    get_default_bhi_thresholds,
    get_bhi_preset_thresholds,
    run_bhi_filtering,
    run_bhi_filtering_with_preset,
    ImageDataset,
    IQANode,
)


def test_optimal_batch_size_calculation():
    """Test optimal batch size calculation based on GPU memory."""
    print_info("=== Testing Optimal Batch Size Calculation ===")

    # Test with different base sizes
    test_cases = [
        (8, 8),  # Base 8 should return 8 if enough memory
        (16, 16),  # Base 16 should return 16 if enough memory
        (32, 16),  # Base 32 should be capped at 16
    ]

    for base_size, expected_max in test_cases:
        optimal = get_optimal_batch_size(base_size)
        print_info(f"Base size: {base_size} ‚Üí Optimal: {optimal}")
        assert (
            optimal <= expected_max
        ), f"Optimal size {optimal} exceeds expected max {expected_max}"

    print_success("‚úì Optimal batch size calculation test passed\n")


def test_threshold_functions():
    """Test threshold utility functions."""
    print_info("=== Testing Threshold Functions ===")

    # Test default thresholds
    defaults = get_default_bhi_thresholds()
    print_info(f"Default thresholds: {defaults}")
    assert all(
        k in defaults for k in ["blockiness", "hyperiqa", "ic9600"]
    ), "Missing threshold keys"
    assert all(0.0 <= v <= 1.0 for v in defaults.values()), "Thresholds out of range"

    # Test preset thresholds
    presets = ["conservative", "moderate", "aggressive"]
    for preset in presets:
        thresholds = get_bhi_preset_thresholds(preset)
        print_info(f"{preset.capitalize()} preset: {thresholds}")
        assert all(
            k in thresholds for k in ["blockiness", "hyperiqa", "ic9600"]
        ), f"Missing keys for {preset}"
        assert all(
            0.0 <= v <= 1.0 for v in thresholds.values()
        ), f"Thresholds out of range for {preset}"

    print_success("‚úì Threshold functions test passed\n")


def test_cuda_optimization_features():
    """Test CUDA optimization features."""
    print_info("=== Testing CUDA Optimization Features ===")

    # Test CUDA availability
    cuda_available = torch.cuda.is_available()
    print_info(f"CUDA available: {cuda_available}")

    if cuda_available:
        # Test GPU memory info
        total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        allocated_memory = torch.cuda.memory_allocated(0) / (1024**3)
        print_info(
            f"GPU Memory: {allocated_memory:.1f}GB used / {total_memory:.1f}GB total"
        )
        assert total_memory > 0, "Invalid total memory"
        assert allocated_memory >= 0, "Invalid allocated memory"

    # Test mixed precision availability
    try:
        with torch.amp.autocast("cuda", enabled=True):
            x = torch.randn(100, 100, device="cuda" if cuda_available else "cpu")
            y = torch.randn(100, 100, device="cuda" if cuda_available else "cpu")
            z = torch.mm(x, y)
            print_info(f"Mixed precision working (dtype: {z.dtype})")
    except Exception as e:
        print_warning(f"Mixed precision test failed: {e}")

    print_success("‚úì CUDA optimization features test passed\n")


def test_dataloader_optimization():
    """Test DataLoader optimization settings."""
    print_info("=== Testing DataLoader Optimization ===")

    # Create a simple dataset
    with tempfile.TemporaryDirectory() as temp_dir:
        # Create some dummy image files
        for i in range(5):
            dummy_file = os.path.join(temp_dir, f"test_{i}.jpg")
            with open(dummy_file, "w") as f:
                f.write("dummy image data")

        # Test ImageDataset creation
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dataset = ImageDataset(temp_dir, device)

        print_info(f"Dataset created with {len(dataset)} items")
        # Note: ImageDataset will skip invalid image files, so len might be 0
        # This is expected behavior for dummy files

        # Test IQANode with optimized DataLoader
        node = IQANode(temp_dir, batch_size=2, dataset=dataset)

        print_info(f"DataLoader created with {len(node.data_loader)} batches")
        # DataLoader might be empty if no valid images, which is fine for testing

        # Verify DataLoader settings
        assert node.data_loader.num_workers == 0, "num_workers should be 0 on Windows"
        assert node.data_loader.pin_memory == (
            device.type == "cpu"
        ), "pin_memory should match device type"

    print_success("‚úì DataLoader optimization test passed\n")


def test_bhi_filtering_workflow():
    """Test complete BHI filtering workflow."""
    print_info("=== Testing BHI Filtering Workflow ===")

    with tempfile.TemporaryDirectory() as temp_dir:
        # Create test directory structure
        test_input = os.path.join(temp_dir, "input")
        test_output = os.path.join(temp_dir, "output")
        os.makedirs(test_input)
        os.makedirs(test_output)

        # Create dummy image files
        for i in range(10):
            dummy_file = os.path.join(test_input, f"test_{i}.jpg")
            with open(dummy_file, "w") as f:
                f.write("dummy image data")

        # Test with report action (dry run)
        try:
            result = run_bhi_filtering(
                input_path=test_input,
                action="report",  # Dry run
                batch_size=2,
                verbose=False,
            )
            print_info("BHI filtering workflow completed successfully")
            assert result is not None, "Should return results"
        except Exception as e:
            print_warning(f"BHI filtering workflow test failed: {e}")
            # This is expected if CUDA models are not available

    print_success("‚úì BHI filtering workflow test passed\n")


def test_error_handling():
    """Test error handling in BHI filtering."""
    print_info("=== Testing Error Handling ===")

    # Test with non-existent directory
    try:
        result = run_bhi_filtering(
            input_path="/non/existent/path", action="report", verbose=False
        )
        assert False, "Should raise an error for non-existent path"
    except Exception as e:
        print_info(f"Correctly caught error for non-existent path: {e}")

    # Test with invalid action
    try:
        result = run_bhi_filtering(
            input_path=".", action="invalid_action", verbose=False
        )
        assert False, "Should raise an error for invalid action"
    except Exception as e:
        print_info(f"Correctly caught error for invalid action: {e}")

    print_success("‚úì Error handling test passed\n")


def test_progress_tracking():
    """Test progress tracking features."""
    print_info("=== Testing Progress Tracking ===")

    # Test that progress tracking functions exist and work
    from dataset_forge.utils.progress_utils import tqdm

    items = list(range(10))
    progress_bar = tqdm(items, desc="Test Progress")

    for item in progress_bar:
        pass  # Just iterate

    print_info("Progress tracking test completed")
    print_success("‚úì Progress tracking test passed\n")


def main():
    """Run all BHI filtering tests."""
    print_info("üîß Starting Comprehensive BHI Filtering Tests...\n")

    test_functions = [
        test_optimal_batch_size_calculation,
        test_threshold_functions,
        test_cuda_optimization_features,
        test_dataloader_optimization,
        test_bhi_filtering_workflow,
        test_error_handling,
        test_progress_tracking,
    ]

    passed = 0
    total = len(test_functions)

    for test_func in test_functions:
        try:
            test_func()
            passed += 1
        except Exception as e:
            print_error(f"‚ùå {test_func.__name__} failed: {e}")

    print_info(f"\n=== Test Results ===")
    print_info(f"Passed: {passed}/{total}")

    if passed == total:
        print_success("üéâ All BHI filtering tests passed!")
    else:
        print_warning(f"‚ö†Ô∏è  {total - passed} tests failed")

    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
