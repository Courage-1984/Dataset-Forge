<h3 align="center">
  Dataset Forge
</h3>
<p align="center">
  <img src="Dataset_Forge_thumb.png" width="300" alt="Dataset Forge Thumbnail"/>
</p>
<div align="center">
  <img src="https://pomf2.lain.la/f/oyxcxpr.png" width="600"/>
</div>

<p align="center"><i>The all-in-one, modular image dataset utility for ML, with a focus on HQ/LQ image pairs for SISR and general computer vision. CLI-first, highly extensible, and packed with advanced tools for dataset curation, analysis, transformation, and validation.</i></p>

---

## âœ¨ TL;DR

> **Dataset Forge** is a comprehensive Python CLI utility for managing, analyzing, and transforming image datasetsâ€”especially High-Quality (HQ) and Low-Quality (LQ) pairs for super-resolution and related ML tasks. It features a beautiful Catppuccin Mocha-themed interface, deep validation, and 40+ powerful operations organized in an intuitive hierarchical menu system.

---

## ğŸš€ Quick Start

### Installation

1. **Clone the repository:**

   ```bash
   git clone <repository-url>
   cd Dataset-Forge
   ```

2. **Windows (Recommended):**

   ```bash
   # Run the automated installer
   install.bat
   ```

3. **Manual Installation:**

   ```bash
   # Create virtual environment
   python -m venv venv

   # Activate virtual environment
   # Windows:
   venv\Scripts\activate
   # Linux/Mac:
   source venv/bin/activate

   # Install PyTorch with CUDA support (if available)
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

   # Install other dependencies
   pip install -r requirements.txt
   ```

4. **Run the application:**
   ```bash
   # Windows:
   run.bat
   # Or manually:
   python main.py
   ```

---

## ğŸª„ Features

### ğŸ¯ **Core & Configuration**

- **Multi-format config support**: JSON, YAML, HCL
- **External tool integration**: [WTP Dataset Destroyer](https://github.com/umzi2/wtp_dataset_destroyer), [traiNNer-redux](https://github.com/the-database/traiNNer-redux)
- **Model management**: List, select, and run upscaling with trained models
- **Validation tools**: Validate HQ/LQ and validation datasets from config
- **Built-in config editors** for .hcl and .yml files
- **User profiles**: Save favorites, presets, and quick access paths

### ğŸ“‚ **Dataset Management**

- **Dataset Creation**: Multiscale dataset generation (DPID), video frame extraction, image tiling
- **Dataset Operations**: Combine, split, extract random pairs, shuffle datasets
- **HQ/LQ Pair Management**: Manual pairing, fuzzy matching, scale correction
- **Clean & Organize**: Visual deduplication, hash-based deduplication, ImageDedup advanced duplicate detection, batch renaming
- **Orientation Organization**: Sort by landscape/portrait/square
- **Size Filtering**: Remove small/invalid image pairs

### ğŸ” **Analysis & Validation**

- **Comprehensive Validation**: Progressive dataset validation suite
- **Rich Reporting**: HTML/Markdown reports with plots and sample images
- **Quality Scoring**: Automated dataset quality assessment (NIQE, etc.)
- **Issue Detection**: Corruption detection, misalignment detection, outlier detection
- **Property Analysis**: Consistency checks, aspect ratio testing, dimension reporting
- **BHI Filtering**: Blockiness, HyperIQA, IC9600 quality assessment
- **Scale Detection**: Find and test HQ/LQ scale relationships

### âœ¨ **Image Processing & Augmentation**

- **Basic Transformations**: Downsampling (DPID, OpenCV, PIL), HDR to SDR conversion, grayscale conversion, alpha channel removal
- **Color & Tone Adjustments**: Brightness, contrast, hue, saturation adjustments
- **Metadata Tools**: EXIF scrubbing, ICC to sRGB conversion
- **Augmentation Pipeline**: Custom transformation recipes, data augmentation
- **Advanced Tiling**: BestTile with Laplacian/IC9600 complexity analysis

### ğŸš€ **Training & Inference**

- **Config Management**: Add, load, edit, and validate configuration files
- **Model Integration**: Run traiNNer-redux, list/run upscaling models
- **Dataset Validation**: Validate training and validation datasets from config
- **External Tools**: Integration with WTP Dataset Destroyer

### ğŸ› ï¸ **Utilities**

- **Visual Comparison**: Side-by-side comparisons, animated GIF comparisons
- **Folder Comparison**: Find missing files between folders
- **Compression Tools**: Image compression, directory archiving
- **Path History**: Smart path management with history and favorites

### ğŸ–¥ï¸ **Beautiful CLI Interface**

- **Catppuccin Mocha Theme**: Beautiful ANSI color scheme
- **Hierarchical Menus**: Intuitive 7-category main menu with logical sub-menus
- **Progress Tracking**: Progress bars, error handling, memory management
- **Smart Input**: Path history, favorites, and intelligent defaults

---

## ğŸ—ï¸ Modular Architecture

Dataset Forge uses a clean, modular architecture for maintainability and extensibility:

### **menus/** - UI Layer

Thin UI layers for each menu category. Only handles user interaction and delegates to actions.

### **actions/** - Business Logic

Core business logic grouped by domain:

- `analysis_actions.py` - Dataset analysis and validation
- `dataset_actions.py` - Dataset operations and management
- `transform_actions.py` - Image transformations and processing
- `config_actions.py` - Configuration management
- `comparison_actions.py` - Visual comparison tools
- `metadata_actions.py` - EXIF and ICC tools
- `report_actions.py` - Rich reporting functionality
- `user_profile_actions.py` - User profile management
- And more...

### **utils/** - Utilities

Reusable helper modules:

- `file_utils.py` - File operations and image type checks
- `input_utils.py` - Input handling and path management
- `printing.py` - Colorful output and formatting
- `color.py` - Catppuccin Mocha color constants
- `menu.py` - Menu rendering helpers
- `path_history.py` - Path history management
- And more...

### **dpid/** - DPID Implementations

Multiple DPID (Degradation Process for Image Downscaling) implementations:

- `basicsr_dpid.py` - BasicSR DPID implementation
- `openmmlab_dpid.py` - OpenMMLab DPID implementation
- `phhofm_dpid.py` - Phhofm's DPID implementation

---

## ğŸ“š Project Structure

```text
Dataset-Forge/
â”œâ”€â”€ main.py                           # Main CLI entry point
â”œâ”€â”€ run.py                            # Runner script
â”œâ”€â”€ install.py                        # Installation script
â”œâ”€â”€ install.bat                       # Windows installer
â”œâ”€â”€ run.bat                          # Windows runner
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ MENU_RESTRUCTURE_SUMMARY.md      # Menu organization details
â”œâ”€â”€ LICENSE                          # Creative Commons CC-BY-SA-4.0
â”œâ”€â”€ Dataset_Forge_thumb.png          # Project thumbnail
â”œâ”€â”€ configs/                         # Configuration files
â”‚   â”œâ”€â”€ _example_config.json         # Example configuration
â”‚   â”œâ”€â”€ _example_user_profile.json   # Example user profile
â”‚   â”œâ”€â”€ _example_community_links.json # Example community links
â”‚   â””â”€â”€ ...                          # User configs (gitignored)
â”œâ”€â”€ reports/                         # Report templates
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ report_template.html.jinja
â”‚       â””â”€â”€ report_template.md.jinja
â””â”€â”€ dataset_forge/                   # Core modules
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ actions/                     # Business logic (25+ files)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ analysis_actions.py      # Dataset analysis & validation
    â”‚   â”œâ”€â”€ dataset_actions.py       # Dataset operations
    â”‚   â”œâ”€â”€ transform_actions.py     # Image transformations
    â”‚   â”œâ”€â”€ config_actions.py        # Configuration management
    â”‚   â”œâ”€â”€ comparison_actions.py    # Visual comparison tools
    â”‚   â”œâ”€â”€ metadata_actions.py      # EXIF & ICC tools
    â”‚   â”œâ”€â”€ report_actions.py        # Rich reporting
    â”‚   â”œâ”€â”€ user_profile_actions.py  # User profile management
    â”‚   â”œâ”€â”€ bhi_filtering_actions.py # Quality assessment
    â”‚   â”œâ”€â”€ tiling_actions.py        # Advanced tiling
    â”‚   â”œâ”€â”€ frames_actions.py        # Video frame extraction
    â”‚   â”œâ”€â”€ augmentation_actions.py  # Data augmentation
    â”‚   â”œâ”€â”€ visual_dedup_actions.py  # Visual deduplication
    â”‚   â”œâ”€â”€ imagededup_actions.py    # ImageDedup integration
    â”‚   â”œâ”€â”€ quality_scoring_actions.py # Quality scoring
    â”‚   â”œâ”€â”€ outlier_detection_actions.py # Outlier detection
    â”‚   â”œâ”€â”€ alpha_actions.py         # Alpha channel tools
    â”‚   â”œâ”€â”€ corruption_actions.py    # Corruption detection
    â”‚   â”œâ”€â”€ de_dupe_actions.py       # Hash-based deduplication
    â”‚   â”œâ”€â”€ batch_rename_actions.py  # Batch renaming
    â”‚   â”œâ”€â”€ hue_adjustment_actions.py # Color adjustments
    â”‚   â”œâ”€â”€ orientation_organizer_actions.py # Orientation organization
    â”‚   â”œâ”€â”€ ic9600_tiling_actions.py # IC9600 tiling
    â”‚   â”œâ”€â”€ compress_actions.py      # Image compression
    â”‚   â”œâ”€â”€ compress_dir_actions.py  # Directory compression
    â”‚   â”œâ”€â”€ folder_compare_actions.py # Folder comparison
    â”‚   â”œâ”€â”€ exif_scrubber_actions.py # EXIF scrubbing
    â”‚   â”œâ”€â”€ operations_actions.py    # Batch operations
    â”‚   â”œâ”€â”€ correct_hq_lq_pairing_actions.py # HQ/LQ pairing
    â”‚   â”œâ”€â”€ dataset_ops_actions.py   # Dataset operations
    â”‚   â””â”€â”€ settings_actions.py      # Settings management
    â”œâ”€â”€ menus/                       # UI layer (15+ files)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ main_menu.py             # Main menu
    â”‚   â”œâ”€â”€ dataset_management_menu.py # Dataset management
    â”‚   â”œâ”€â”€ analysis_validation_menu.py # Analysis & validation
    â”‚   â”œâ”€â”€ image_processing_menu.py # Image processing
    â”‚   â”œâ”€â”€ training_inference_menu.py # Training & inference
    â”‚   â”œâ”€â”€ utilities_menu.py        # Utilities
    â”‚   â”œâ”€â”€ system_settings_menu.py  # System settings
    â”‚   â”œâ”€â”€ user_profile_menu.py     # User profile
    â”‚   â”œâ”€â”€ visual_dedup_menu.py     # Visual deduplication
    â”‚   â”œâ”€â”€ imagededup_menu.py       # ImageDedup menu
    â”‚   â”œâ”€â”€ correct_hq_lq_pairing_menu.py # HQ/LQ pairing
    â”‚   â”œâ”€â”€ compress_menu.py         # Compression
    â”‚   â”œâ”€â”€ compress_dir_menu.py     # Directory compression
    â”‚   â”œâ”€â”€ links_menu.py            # Community links
    â”‚   â”œâ”€â”€ history_log_menu.py      # History logs
    â”‚   â””â”€â”€ session_state.py         # Session state
    â”œâ”€â”€ utils/                       # Utilities (12+ files)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ file_utils.py            # File operations
    â”‚   â”œâ”€â”€ input_utils.py           # Input handling
    â”‚   â”œâ”€â”€ printing.py              # Output formatting
    â”‚   â”œâ”€â”€ color.py                 # Color constants
    â”‚   â”œâ”€â”€ menu.py                  # Menu rendering
    â”‚   â”œâ”€â”€ path_history.py          # Path history
    â”‚   â”œâ”€â”€ history_log.py           # Operation logging
    â”‚   â”œâ”€â”€ image_ops.py             # Image operations
    â”‚   â”œâ”€â”€ dpid_phhofm.py           # DPID utilities
    â”‚   â”œâ”€â”€ ic9600_tiling.py         # IC9600 utilities
    â”‚   â”œâ”€â”€ upscale_script.py        # Upscaling utilities
    â”‚   â””â”€â”€ logging_utils.py         # Logging utilities
    â””â”€â”€ dpid/                        # DPID implementations
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ basicsr_dpid.py          # BasicSR DPID
        â”œâ”€â”€ openmmlab_dpid.py        # OpenMMLab DPID
        â””â”€â”€ phhofm_dpid.py           # Phhofm DPID
```

---

## ğŸ® Menu Structure

The application features an intuitive hierarchical menu system:

### Main Menu (7 Categories)

```
[ 1 ] ğŸ“‚ Dataset Management     (Create, build, and modify dataset structures)
[ 2 ] ğŸ” Analysis & Validation  (Inspect quality, find issues, and generate reports)
[ 3 ] âœ¨ Image Processing       (Apply transformations and create variations)
[ 4 ] ğŸš€ Training & Inference   (Manage configs and run models)
[ 5 ] ğŸ› ï¸ Utilities             (Comparison, compression, and other tools)
[ 6 ] âš™ï¸ System & Settings     (Application settings, user profiles, and logs)
[ 0 ] ğŸšª Exit
```

### Detailed Sub-Menu Structure

#### ğŸ“‚ Dataset Management

- **Dataset Creation & Modification**
  - Create Multiscale Dataset (DPID)
  - Extract Frames from Video
  - Image Tiling (BestTile, IC9600)
- **Combine or Split Datasets**
  - Combine Multiple Datasets
  - Split and Adjust Dataset
- **Manage HQ/LQ Pairs**
  - Create/Correct Manual Pairings
  - Find Pairs with Fuzzy Matching
  - Extract Random Pairs
  - Shuffle Image Pairs
- **Clean & Organize**
  - Visual De-duplication (CLIP/LPIPS)
  - De-Duplicate (File Hash)
  - ImageDedup - Advanced Duplicate Detection
  - Batch Rename
  - Remove Image Pairs by Size
  - Organize by Orientation

#### ğŸ” Analysis & Validation

- **Dataset Analysis & Reporting**
  - Run Comprehensive Validation Suite
  - Generate Detailed Report (HTML/Markdown)
  - Automated Dataset Quality Scoring
- **Find & Fix Issues**
  - Verify & Fix Image Corruption
  - Find Misaligned Image Pairs
  - Find Outliers & Anomalies
  - Find Images with Alpha Channel
- **Analyze Properties**
  - Check Dataset Consistency
  - Check/Test Aspect Ratios
  - Find & Test HQ/LQ Scale
  - Report Image Dimensions
  - BHI Filtering Analysis

#### âœ¨ Image Processing & Augmentation

- **Basic Transformations**
  - Downsample Images (DPID, OpenCV, PIL)
  - Convert HDR to SDR
  - Convert to Grayscale
  - Remove Alpha Channel
- **Color & Tone Adjustments**
  - General Color/Tone Adjustments
  - Hue/Brightness/Contrast
- **Metadata**
  - Scrub EXIF Data
  - Convert ICC Profile to sRGB
- **Augmentation**
  - Run Augmentation Pipeline/Recipes
  - Apply Custom Transformations

#### ğŸš€ Training & Inference

- **Manage Config Files (.hcl, .yml)**
  - Add/Load Config File
  - Edit Config File
  - View Config Info
- **Validate Dataset from Config**
  - Validate Training HQ/LQ Dataset
  - Validate Validation HQ/LQ Dataset
- **Run Training / Models**
  - Run traiNNer-redux
  - List/Run Upscale with Model
  - Run wtp_dataset_destroyer

#### ğŸ› ï¸ Utilities

- **Compare Images / Folders**
  - Create Comparison Images (Side-by-side)
  - Create GIF Comparison
  - Compare Folder Contents
- **Compress Images / Directory**
  - Compress Images
  - Compress Directory

#### âš™ï¸ System & Settings

- **Application Settings & Information**
  - Set Working Directories (HQ/LQ Folders)
  - User Profile Management
  - View Change/History Log
  - Links (Community & Personal)

---

## âš™ï¸ Configuration

Dataset Forge supports multiple configuration formats:

### JSON Example

```json
{
  "model_name": "my_model",
  "scale": 2.0,
  "hq_path": "/path/to/hq/images",
  "lq_path": "/path/to/lq/images",
  "yml_path": "/path/to/trainner.yml",
  "hcl_path": "/path/to/wtp.hcl",
  "min_lq_w": 96,
  "min_lq_h": 96
}
```

### User Profile Example

```json
{
  "name": "default",
  "favorites": ["Dataset Management", "Analysis & Validation"],
  "presets": [
    {
      "name": "Quick Validation",
      "type": "validation",
      "settings": { "sample_count": 10, "max_quality_images": 50 }
    }
  ],
  "favorite_paths": ["/path/to/datasets", "/path/to/models"],
  "settings": {
    "default_tile_size": 512,
    "default_quality": 85
  }
}
```

---

## ğŸ› ï¸ Requirements

### System Requirements

- **Python**: 3.8+
- **CUDA**: 12.1+ (for GPU acceleration)
- **RAM**: 8GB+ (16GB+ recommended for large datasets)
- **Storage**: SSD recommended for faster I/O

### Core Dependencies

```txt
# Core image processing
numpy<2
opencv-python
Pillow
tqdm
imageio
pyyaml
ffmpeg

# ML/AI frameworks
torch
torchvision
torchaudio
spandrel
spandrel_extra_arches
chainner-ext

# Quality assessment
pyiqa
timm
lpips
open-clip-torch

# Utilities
imagehash
PyExifTool
matplotlib
seaborn
jinja2
webbrowser
imagededup

# Custom packages
pipeline
pepeline
pepedpid
```

### Optional Dependencies

- **ExifTool**: For EXIF metadata handling
- **FFmpeg**: For video processing and HDR conversion
- **CUDA Toolkit**: For GPU acceleration

---

## ğŸš€ Usage Examples

### Basic Workflow

1. **Set up your workspace:**

   ```
   System & Settings â†’ Set Working Directories
   ```

2. **Create a dataset:**

   ```
   Dataset Management â†’ Create Dataset from Source â†’ Create Multiscale Dataset
   ```

3. **Validate your dataset:**

   ```
   Analysis & Validation â†’ Run Comprehensive Validation Suite
   ```

4. **Process images:**

   ```
   Image Processing â†’ Basic Transformations â†’ Downsample Images
   ```

5. **Generate a report:**
   ```
   Analysis & Validation â†’ Generate Detailed Report
   ```

### Advanced Workflows

#### Super-Resolution Dataset Preparation

1. Create multiscale dataset with DPID
2. Run comprehensive validation
3. Apply quality filtering (BHI)
4. Generate training/validation splits
5. Create rich HTML report

#### Video Frame Extraction

1. Extract frames using deep embeddings
2. Filter by quality and similarity
3. Organize by orientation
4. Create HQ/LQ pairs
5. Validate alignment and scale

#### Dataset Augmentation

1. Load existing dataset
2. Apply augmentation pipeline
3. Quality assessment
4. Visual deduplication
5. Export augmented dataset

---

## ğŸ”§ Advanced Features

### DPID (Degradation Process for Image Downscaling)

Multiple implementations for realistic image degradation:

- **BasicSR DPID**: Industry-standard implementation
- **OpenMMLab DPID**: Research-focused implementation
- **Phhofm DPID**: Custom implementation

### BHI Filtering

Quality assessment using multiple metrics:

- **Blockiness**: Detect compression artifacts
- **HyperIQA**: Perceptual quality assessment
- **IC9600**: Neural quality assessment

### Advanced Tiling

Intelligent image tiling with complexity analysis:

- **Laplacian Complexity**: Traditional complexity measure
- **IC9600 Complexity**: Neural complexity assessment
- **BestTile Algorithm**: Optimal tile selection

### Visual Deduplication

Deep learning-based duplicate detection:

- **CLIP Embeddings**: Fast semantic similarity
- **LPIPS**: Perceptual similarity
- **Configurable Thresholds**: Adjustable sensitivity

### ImageDedup Integration

Advanced duplicate detection using the imagededup library:

- **Multiple Hash Methods**: PHash, DHash, AHash, WHash
- **Configurable Thresholds**: Adjustable distance thresholds
- **HQ/LQ Pair Support**: Handle paired datasets
- **Visual Reports**: Generate duplicate analysis reports
- **Flexible Operations**: Find, remove, or move duplicates
- **Dry Run Mode**: Preview changes before applying

---

## ğŸ› Troubleshooting

### Common Issues

1. **CUDA Out of Memory**

   - Reduce batch sizes in settings
   - Use CPU-only mode for large datasets
   - Process images in smaller batches

2. **Missing Dependencies**

   - Run `pip install -r requirements.txt`
   - Install PyTorch with correct CUDA version
   - Install ExifTool for metadata features

3. **Path Issues**

   - Use absolute paths for large datasets
   - Check file permissions
   - Ensure paths don't contain special characters

4. **Performance Issues**
   - Use SSD storage for better I/O
   - Increase RAM if available
   - Use GPU acceleration when possible

### Getting Help

- Check the operation logs in the System & Settings menu
- Review the comprehensive validation reports
- Use the built-in help system in each menu

---

## ğŸ¤ Contributing

Dataset Forge is designed with a modular architecture for easy contribution:

1. **Add new actions**: Create new files in `dataset_forge/actions/`
2. **Add new menus**: Create new files in `dataset_forge/menus/`
3. **Add new utilities**: Create new files in `dataset_forge/utils/`
4. **Follow the architecture**: Keep UI, business logic, and utilities separate

### Development Setup

```bash
git clone <repository-url>
cd Dataset-Forge
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
python main.py
```

---

## ğŸ’œ Credits

- Thanks [Kim2091](https://github.com/Kim2091)â¤ï¸ for [helpful-scripts](https://github.com/Kim2091/helpful-scripts)
- Thanks [umzi2](https://github.com/umzi2)â¤ï¸ for [WTP Dataset Destroyer](https://github.com/umzi2/wtp_dataset_destroyer) & [Dataset_Preprocessing](https://github.com/umzi2/Dataset_Preprocessing)
- Thanks [the-database](https://github.com/the-database)â¤ï¸ for [traiNNer-redux](https://github.com/the-database/traiNNer-redux)
- Thanks [Phhofm](https://github.com/Phhofm)â¤ï¸ for [sisr](https://github.com/Phhofm/sisr)

---

## ğŸ“„ License

**Creative Commons Attribution Share Alike 4.0 International (CC-BY-SA-4.0)**

This license allows you to:

- Share: Copy and redistribute the material in any medium or format
- Adapt: Remix, transform, and build upon the material
- Attribution: You must give appropriate credit
- Share Alike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license

---

<p align="center">
  <b>Enjoy your dataset journey! ğŸš€</b>
</p>
